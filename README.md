The primary objective of this project was to demystify the mathematics powering Deep Learning. Guided by the book Grokking Deep Learning by Andrew Trask, I sought to move beyond high-level intuition by building a neural network framework entirely from scratch.

While implementing the code was a success, the true understanding came from experimentation. I validated the framework on the MNIST dataset with good results. I also explored text and art generation, though these tasks were computationally limited by CPU constraints.

Ultimately, this hands-on experience bridged the gap between theory and practice, significantly deepening my understanding of neural network mechanics. Special thanks to the author of Grokking Deep Learning for the clear and intuitive explanations.
